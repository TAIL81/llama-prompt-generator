import json
import os
import re

from openai import OpenAI
from groq import Groq
from dotenv import load_dotenv
from pathlib import Path

# ç’°å¢ƒå¤‰æ•°ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã® .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ã¾ã™
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®šç¾©ã—ã¾ã™
default_system = "You are a helpful and knowledgeable assistant who is able to provide detailed and accurate information on a wide range of topics. You are also able to provide clear and concise answers to questions and are always willing to go the extra mile to help others."
Groq_default_system = default_system
OpenRouter_default_system = default_system

# å¿œç­”è©•ä¾¡ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
evaluate_response_prompt_template = """
You are an expert in linguistics and able to observe subtle differences in content between two paragraphs. Your task is to analyze responses from OpenAI and Llama and provide detailed feedback.

Here are the OpenAI response: 
<response>
{_OpenAI}
</response>

Here are the Llama response:
<response>
{_Bedrock}
</response>

Please follow these steps:
1. Carefully analyze both responses in terms of content accuracy, logical organization, and expression style.
2. Summarize the differences between the Llama response and the OpenAI response.
3. Provide recommendations on how the Llama response could be refactored to better align with the OpenAI response.
4. Encapsulate your analysis, including the differences, within <auto_feedback></auto_feedback> tags using bullet points.
5. Encapsulate recommendations, within <recommendation></recommendation> tags using bullet points.
""".strip()

# æ”¹è¨‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
generate_revised_prompt_template = """
You are an expert in prompt engineering for both OpenAI and Llama model and able to follow the human feedback to adjust the prompt to attain the optimal effect, you will be given the original Llama prompt, responses from OpenAI, responses from Llama and human feedback to revise the Llama prompt.

Here are the original Llama prompt: 
<prompt>
{_prompt}
</prompt>

Here are the OpenAI response:
<response>
{_OpenAI}
</response>

Here are the Llama response:
<response>
{_Bedrock}
</response>

Here are the human feedback:
<evaluation_summary>
{_feedback}
</evaluation_summary>

Please analyze whether Llama's response strictly aligns with OpenAI's response based on the human feedback. Then, consider how the original Llama prompt can be improved accordingly. Your revised prompt should only involve slight adjustments and must not drastically change the original prompt. Use the human feedback to guide your revision.

Finally, provide the revised prompt within the following XML tags:

<revised_prompt>
[Your revised prompt]
</revised_prompt>
""".strip()

# APIã‚­ãƒ¼ã¨ãƒ™ãƒ¼ã‚¹URLã‚’ (.env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ) ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ã¾ã™
openai_api_key = os.getenv("OPENAI_API_KEY")
openai_base_url = os.getenv("OPENAI_BASE_URL", "https://openrouter.ai/api/v1")
groq_api_key = os.getenv("GROQ_API_KEY")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–ã¨è©•ä¾¡ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹
class Alignment:
    def __init__(self):
        try:
            self.openrouter_client = OpenAI(
                base_url=openai_base_url,
                api_key=openai_api_key,
            )
            # # è¿½åŠ ï¼šå®Ÿéš›ã®base_urlã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
            # if self.openrouter_client:
            #     print(f"ğŸ” [DEBUG] Initialized OpenRouter client with base_url: {self.openrouter_client.base_url}")
        except Exception as e:
            # APIã‚­ãƒ¼ãŒãªã„å ´åˆã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯Noneã«ãªã‚Šã¾ã™
            print(f"OpenRouter client initialization failed: {e}") # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¿½åŠ 
            self.openrouter_client = None
        try:
            self.groq_client = Groq(api_key=groq_api_key)
        except Exception as e:
            # APIã‚­ãƒ¼ãŒãªã„å ´åˆã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯Noneã«ãªã‚Šã¾ã™
            print(f"Groq client initialization failed: {e}") # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¿½åŠ 
            self.groq_client = None

    def generate_groq_response(self, prompt, model_id):
        """
        Groq APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

        Args:
            prompt (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
            model_id (str): ä½¿ç”¨ã™ã‚‹Groqãƒ¢ãƒ‡ãƒ«ã®IDã€‚

        Returns:
            str: Groqãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚
        """
        if not self.groq_client:
            return "GroqError: API client not initialized. Check GROQ_API_KEY."
        try:
            completion = self.groq_client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": Groq_default_system},
                    {"role": "user", "content": prompt},
                ],
            )
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
            if hasattr(completion, 'choices') and completion.choices and hasattr(completion.choices[0], 'message'):
                 msg = completion.choices[0].message
                 return msg.content if hasattr(msg, 'content') else "Error: Content missing in Groq response"
            else:
                return "Error: Invalid response structure from Groq API"
        except Exception as e:
            return f"Groq API Error: {str(e)}"

    def generate_openrouter_response(self, prompt, model_id):
        """
        OpenRouter API (OpenAIäº’æ›) ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

        Args:
            prompt (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
            model_id (str): ä½¿ç”¨ã™ã‚‹OpenRouterãƒ¢ãƒ‡ãƒ«ã®IDã€‚

        Returns:
            str: OpenRouterãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚
        """
        if not self.openrouter_client:
            return "OpenRouterError: API client not initialized. Check OPENAI_API_KEY."
        try:
            # print(f"ğŸ” [DEBUG] APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡: model={model_id}, prompt_length={len(prompt)}")
            completion = self.openrouter_client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": OpenRouter_default_system},
                    {"role": "user", "content": prompt},
                ],
            )

            # APIã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–‡å­—åˆ—å‹ã®å ´åˆã€ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦å‡¦ç†ã—ã¾ã™
            if isinstance(completion, str):
                # print(f"ğŸ” [DEBUG] OpenRouter API returned a string: {completion}")
                return f"OpenRouter API Error: Received unexpected string response: {completion}"

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ãƒ‡ãƒãƒƒã‚°
            # print(f"ğŸ” [DEBUG] ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ—: {type(completion)}")
            # print(f"ğŸ” [DEBUG] ãƒ¬ã‚¹ãƒãƒ³ã‚¹å±æ€§: {dir(completion)}")

            if hasattr(completion, 'choices'):
                # print(f"ğŸ” [DEBUG] choicesæ•°: {len(completion.choices)}")
                if completion.choices and len(completion.choices) > 0: # choicesãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
                    first_choice = completion.choices[0]
                    # print(f"ğŸ” [DEBUG] æœ€åˆã®choiceã‚¿ã‚¤ãƒ—: {type(first_choice)}")
                    # print(f"ğŸ” [DEBUG] æœ€åˆã®choiceå±æ€§: {dir(first_choice)}")
                    if hasattr(first_choice, 'message'):
                        msg = first_choice.message
                        # print(f"ğŸ” [DEBUG] messageã‚¿ã‚¤ãƒ—: {type(msg)}")
                        # print(f"ğŸ” [DEBUG] messageå±æ€§: {dir(msg)}")
                        if hasattr(msg, 'content'):
                            return msg.content
            # ä¸Šè¨˜ã®ã„ãšã‚Œã®æ¡ä»¶ã«ã‚‚ä¸€è‡´ã—ãªã„å ´åˆã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™
            error_message = "Error: Invalid or empty response structure from OpenRouter API."
            # print(f"ğŸ” [DEBUG] {error_message} Response: {completion}") # è©³ç´°ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
            return error_message
        except Exception as e:
            return f"OpenRouter API Error: {str(e)}"

    def stream_groq_response(self, prompt, model_id, output_component):
        # TODO: Gradioã®å‡ºåŠ›ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¸ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã‚’å®Ÿè£…ã™ã‚‹
        if not self.groq_client:
            output_component.update("GroqError: API client not initialized. Check GROQ_API_KEY.")
            return
        try:
            stream = self.groq_client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": Groq_default_system},
                    {"role": "user", "content": prompt},
                ],
                stream=True,
            )
            for chunk in stream:
                if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
                    output_component.update(chunk.choices[0].delta.content, append=True)
        except Exception as e:
            output_component.update(f"Groq API Error during streaming: {str(e)}")


    def stream_openrouter_response(self, prompt, model_id, output_component):
        # TODO: Gradioã®å‡ºåŠ›ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¸ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã‚’å®Ÿè£…ã™ã‚‹
        if not self.openrouter_client:
            output_component.update("OpenRouterError: API client not initialized. Check OPENAI_API_KEY.")
            return
        try:
            stream = self.openrouter_client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": OpenRouter_default_system},
                    {"role": "user", "content": prompt},
                ],
                stream=True,
            )
            for chunk in stream:
                if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content is not None:
                    output_component.update(chunk.choices[0].delta.content, append=True)
        except Exception as e:
             output_component.update(f"OpenRouter API Error during streaming: {str(e)}")


    def invoke_prompt(
        self,
        original_prompt_replace,
        revised_prompt_replace,
        original_prompt,
        revised_prompt,
        openrouter_model_id,
        groq_model_id,
    ):
        """
        å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨æ”¹è¨‚ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãã‚Œãã‚ŒOpenRouterã¨Groqã§å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚

        Args:
            original_prompt_replace (str): å¤‰æ•°ãŒç½®æ›ã•ã‚ŒãŸå…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
            revised_prompt_replace (str): å¤‰æ•°ãŒç½®æ›ã•ã‚ŒãŸæ”¹è¨‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
            original_prompt (str): å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç½®æ›å‰ï¼‰ã€‚
            revised_prompt (str): æ”¹è¨‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç½®æ›å‰ï¼‰ã€‚
            openrouter_model_id (str): OpenRouterã§ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«IDã€‚
            groq_model_id (str): Groqã§ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«IDã€‚

        Returns:
            tuple: (OpenRouterã‹ã‚‰ã®å¿œç­”, Groqã‹ã‚‰ã®å¿œç­”)
        """
        # ç½®æ›å¾Œã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç©ºã®å ´åˆã€ç½®æ›å‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™
        if len(original_prompt_replace) == 0:
            original_prompt_replace = original_prompt
        if len(revised_prompt_replace) == 0:
            revised_prompt_replace = revised_prompt

        # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã®å…·ä½“çš„ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if self.openrouter_client is None:
            openai_result = "OpenRouterError: API client not initialized. Check OPENAI_API_KEY and OPENAI_BASE_URL."
        else:
            # generate_openrouter_responseã‹ã‚‰ã®æˆ»ã‚Šå€¤ã‚’ãƒã‚§ãƒƒã‚¯
            openai_result = self.generate_openrouter_response(
                original_prompt_replace, openrouter_model_id
            )
            # generate_openrouter_responseãŒã‚¨ãƒ©ãƒ¼æ–‡å­—åˆ—ã‚’è¿”ã™å ´åˆãŒã‚ã‚‹ãŸã‚ã€ã“ã“ã§å‡¦ç†
            if isinstance(openai_result, str) and openai_result.startswith("OpenRouter API Error:"):
                pass # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãã®ã¾ã¾ä½¿ç”¨

        if self.groq_client is None:
            groq_result = "GroqError: API client not initialized. Check GROQ_API_KEY."
        else:
            # generate_groq_responseã‹ã‚‰ã®æˆ»ã‚Šå€¤ã‚’ãƒã‚§ãƒƒã‚¯
            groq_result = self.generate_groq_response(
                revised_prompt_replace, groq_model_id
            )
            # generate_groq_responseãŒã‚¨ãƒ©ãƒ¼æ–‡å­—åˆ—ã‚’è¿”ã™å ´åˆãŒã‚ã‚‹ãŸã‚ã€ã“ã“ã§å‡¦ç†
            if isinstance(groq_result, str) and groq_result.startswith("Groq API Error:"):
                pass # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãã®ã¾ã¾ä½¿ç”¨

        return openai_result, groq_result

    def evaluate_response(self, openai_output, groq_output, eval_model_id):
        """
        OpenAIã¨Groqã®å¿œç­”ã‚’æ¯”è¼ƒè©•ä¾¡ã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

        Args:
            openai_output (str): OpenAI (OpenRouter) ã‹ã‚‰ã®å¿œç­”ã€‚
            groq_output (str): Groqã‹ã‚‰ã®å¿œç­”ã€‚
            eval_model_id (str): è©•ä¾¡ã«ä½¿ç”¨ã™ã‚‹Groqãƒ¢ãƒ‡ãƒ«ã®IDã€‚

        Returns:
            str: è‡ªå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ¨å¥¨äº‹é …ã‚’å«ã‚€æ–‡å­—åˆ—ã€‚
        """
        if not self.groq_client:
            return "GroqError: API client for evaluation not initialized. Check GROQ_API_KEY."
        revised_prompt = evaluate_response_prompt_template.format(
            _OpenAI=openai_output, _Bedrock=groq_output
        )
        # generate_groq_responseã‹ã‚‰ã®æˆ»ã‚Šå€¤ã‚’ãƒã‚§ãƒƒã‚¯
        groq_result = self.generate_groq_response(revised_prompt, eval_model_id)
        if isinstance(groq_result, str) and groq_result.startswith("Groq API Error:"):
             return f"Evaluation Error: {groq_result}" # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™

        # ç”Ÿæˆã•ã‚ŒãŸçµæœã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ¨å¥¨äº‹é …ã‚’æŠ½å‡ºã—ã¾ã™
        pattern = r"<auto_feedback>(.*?)</auto_feedback>"
        feedback_match = re.findall(pattern, groq_result, re.DOTALL)
        feedback = feedback_match[0] if feedback_match else "Feedback not found."

        pattern = r"<recommendation>(.*?)</recommendation>"
        recommendation_match = re.findall(pattern, groq_result, re.DOTALL)
        recommendation = recommendation_match[0] if recommendation_match else "Recommendation not found."

        return feedback + f"\n<recommendation>{recommendation}</recommendation>"

    def insert_kv(self, user_prompt, kv_string):
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼æ–‡å­—åˆ—ã«åŸºã¥ã„ã¦ç½®æ›ã—ã¾ã™ã€‚

        Args:
            user_prompt (str): ç½®æ›å¯¾è±¡ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
            kv_string (str): "key1:value1;key2:value2" å½¢å¼ã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼æ–‡å­—åˆ—ã€‚

        Returns:
            str: ç½®æ›å¾Œã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
        """
        # Split the key-value string by ';' to get individual pairs
        kv_pairs = kv_string.split(";")
        for pair in kv_pairs:
            if ":" in pair:
                key, value = pair.split(":", 1)  # Only split on the first ':'
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã® {key} å½¢å¼ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’ value ã§ç½®æ›ã—ã¾ã™
                user_prompt = user_prompt.replace(f"{{{key}}}", value)
        return user_prompt

    def generate_revised_prompt(
        self, feedback, prompt, openai_response, groq_response, eval_model_id
    ):
        """
        ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãŠã‚ˆã³ä¸¡ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ã«åŸºã¥ã„ã¦ã€æ”¹è¨‚ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

        Args:
            feedback (str): ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã®ãŸã‚ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€‚
            prompt (str): å…ƒã®Llama (Groq) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
            openai_response (str): OpenAI (OpenRouter) ã‹ã‚‰ã®å¿œç­”ã€‚
            groq_response (str): Llama (Groq) ã‹ã‚‰ã®å¿œç­”ã€‚
            eval_model_id (str): ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹è¨‚ã«ä½¿ç”¨ã™ã‚‹Groqãƒ¢ãƒ‡ãƒ«ã®IDã€‚

        Returns:
            str: æ”¹è¨‚ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
        """
        pattern = r"<recommendation>(.*?)</recommendation>"
        matches = re.findall(pattern, feedback, re.DOTALL)
        if len(matches):
            feedback = matches[0]
        revised_prompt = generate_revised_prompt_template.format(
            _feedback=feedback,
            _prompt=prompt,
            _OpenAI=openai_response,
            _Bedrock=groq_response,
        )
        if not self.groq_client:
            return "GroqError: API client for prompt revision not initialized. Check GROQ_API_KEY."
        # generate_groq_responseã‹ã‚‰ã®æˆ»ã‚Šå€¤ã‚’ãƒã‚§ãƒƒã‚¯
        groq_result = self.generate_groq_response(revised_prompt, eval_model_id)
        if isinstance(groq_result, str) and groq_result.startswith("Groq API Error:"):
             return f"Prompt Revision Error: {groq_result}" # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™

        # ç”Ÿæˆã•ã‚ŒãŸçµæœã‹ã‚‰æ”¹è¨‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŠ½å‡ºã—ã¾ã™
        pattern = r"<revised_prompt>(.*?)</revised_prompt>"
        matches = re.findall(pattern, groq_result, re.DOTALL)
        matches = matches[0] if matches else "Revised prompt not found."
        return matches.strip()
